{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        ..., \n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0]],\n",
       "\n",
       "       [[ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        ..., \n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0]],\n",
       "\n",
       "       [[ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        ..., \n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0]],\n",
       "\n",
       "       ..., \n",
       "       [[80, 89, 22],\n",
       "        [80, 89, 22],\n",
       "        [80, 89, 22],\n",
       "        ..., \n",
       "        [80, 89, 22],\n",
       "        [80, 89, 22],\n",
       "        [80, 89, 22]],\n",
       "\n",
       "       [[80, 89, 22],\n",
       "        [80, 89, 22],\n",
       "        [80, 89, 22],\n",
       "        ..., \n",
       "        [80, 89, 22],\n",
       "        [80, 89, 22],\n",
       "        [80, 89, 22]],\n",
       "\n",
       "       [[80, 89, 22],\n",
       "        [80, 89, 22],\n",
       "        [80, 89, 22],\n",
       "        ..., \n",
       "        [80, 89, 22],\n",
       "        [80, 89, 22],\n",
       "        [80, 89, 22]]], dtype=uint8)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "\n",
    "env = gym.make('SpaceInvaders-v0')\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before processing: (210, 160, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f16b06bf860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After processing: (84, 84, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f15f0963dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess(observation):\n",
    "    observation = cv2.cvtColor(cv2.resize(observation, (84, 110)), cv2.COLOR_BGR2GRAY)\n",
    "    observation = observation[26:110, :] # removing the first 26 rows as they only contain the score\n",
    "    ret, observation = cv2.threshold(observation, 1, 255, cv2.THRESH_BINARY)\n",
    "    return np.reshape(observation,(84, 84, 1))\n",
    "\n",
    "\n",
    "action0 = 0  # do nothing\n",
    "observation0, reward0, terminal, info = env.step(action0)\n",
    "print(\"Before processing: \" + str(np.array(observation0).shape))\n",
    "plt.imshow(np.array(observation0))\n",
    "plt.show()\n",
    "observation0 = preprocess(observation0)\n",
    "print(\"After processing: \" + str(np.array(observation0).shape))\n",
    "plt.imshow(np.array(np.squeeze(observation0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Double_DQN():\n",
    "    def __init__(self,\n",
    "                 output_size):\n",
    "        self.output_size = output_size\n",
    "        self.build_layers()\n",
    "        \n",
    "    def build_layers(self):\n",
    "        self.input_layer = tf.placeholder(dtype=tf.float32, shape=[None, 84, 84, 1])\n",
    "        \n",
    "        conv1 = tf.layers.conv2d(\n",
    "            inputs=self.input_layer,\n",
    "            filters=32,\n",
    "            kernel_size=[8, 8],\n",
    "            strides=[4, 4],\n",
    "            padding=\"valid\",\n",
    "            activation=tf.nn.relu)\n",
    "        \n",
    "        conv2 = tf.layers.conv2d(\n",
    "            inputs=conv1,\n",
    "            filters=64,\n",
    "            kernel_size=[4, 4],\n",
    "            strides=[2, 2],\n",
    "            padding=\"valid\",\n",
    "            activation=tf.nn.relu)\n",
    "        \n",
    "        conv3 = tf.layers.conv2d(\n",
    "            inputs=conv2,\n",
    "            filters=64,\n",
    "            kernel_size=[3, 3],\n",
    "            strides=[1, 1],\n",
    "            padding=\"valid\",\n",
    "            activation=tf.nn.relu)\n",
    "        \n",
    "        conv4 = tf.layers.conv2d(\n",
    "            inputs=conv3,\n",
    "            filters=self.output_size,\n",
    "            kernel_size=[7, 7],\n",
    "            strides=[1, 1],\n",
    "            padding=\"valid\",\n",
    "            activation=tf.nn.relu)\n",
    "        \n",
    "#         #We take the output from the final convolutional layer and split it into separate advantage and value streams.\n",
    "#         streamAC, streamVC = tf.split(conv4, 2, 3)\n",
    "#         self.streamA = slim.flatten(self.streamAC)\n",
    "#         self.streamV = slim.flatten(self.streamVC)\n",
    "#         xavier_init = tf.contrib.layers.xavier_initializer()\n",
    "#         self.AW = tf.Variable(xavier_init([h_size // 2, env.actions]))\n",
    "#         self.VW = tf.Variable(xavier_init([h_size // 2, 1]))\n",
    "#         self.Advantage = tf.matmul(self.streamA, self.AW)\n",
    "#         self.Value = tf.matmul(self.streamV, self.VW)\n",
    "        \n",
    "#         #Then combine them together to get our final Q-values.\n",
    "#         self.Qout = self.Value + tf.subtract(self.Advantage,tf.reduce_mean(self.Advantage,axis=1,keep_dims=True))\n",
    "#         self.predict = tf.argmax(self.Qout,1)\n",
    "        \n",
    "        self.Q = conv4\n",
    "        self.prediction = tf.argmax(self.Q, 1)\n",
    "        \n",
    "        #Below we obtain the loss by taking the sum of squares difference between the target and prediction Q values.\n",
    "        self.targetQ = tf.placeholder(shape=[None], dtype=tf.float32)\n",
    "        self.actions = tf.placeholder(shape=[None], dtype=tf.int32)\n",
    "        self.actions_onehot = tf.one_hot(self.actions, env.action_space.n, dtype=tf.float32)\n",
    "        \n",
    "#         self.Q = tf.reduce_sum(tf.multiply(self.out, self.actions_onehot), axis=1)\n",
    "        self.loss = tf.reduce_mean(tf.square(self.targetQ - self.Q))\n",
    "        self.train_op = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(self.loss)\n",
    "\n",
    "        \n",
    "class experience_buffer():\n",
    "    def __init__(self, buffer_size = 50000):\n",
    "        self.buffer = []\n",
    "        self.buffer_size = buffer_size\n",
    "    \n",
    "    def add(self, experience):\n",
    "        if len(self.buffer) + len(experience) >= self.buffer_size:\n",
    "            self.buffer[0:(len(experience) + len(self.buffer)) % self.buffer_size] = []\n",
    "        self.buffer.extend(experience)\n",
    "            \n",
    "    def sample(self, size):\n",
    "        return np.reshape(np.array(random.sample(self.buffer, size)), [size, 5])\n",
    "\n",
    "    \n",
    "def updateTargetGraph(tfVars,tau):\n",
    "    total_vars = len(tfVars)\n",
    "    op_holder = []\n",
    "    for idx,var in enumerate(tfVars[0:total_vars//2]):\n",
    "        op_holder.append(tfVars[idx+total_vars//2].assign((var.value()*tau) + ((1-tau)*tfVars[idx+total_vars//2].value())))\n",
    "    return op_holder\n",
    "\n",
    "\n",
    "def updateTarget(op_holder,sess):\n",
    "    for op in op_holder:\n",
    "        sess.run(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 0.5 1\n",
      "1000 1.0 1\n",
      "1500 0.0 1\n",
      "2000 0.0 1\n",
      "2500 0.5 1\n",
      "3000 0.0 1\n",
      "3500 0.0 1\n",
      "4000 0.0 1\n",
      "4500 0.0 1\n",
      "5000 0.5 1\n",
      "5500 1.0 1\n",
      "6000 0.0 1\n",
      "6500 0.0 1\n",
      "7000 0.0 1\n",
      "7500 0.0 1\n",
      "8000 0.0 1\n",
      "8500 0.0 1\n",
      "9000 0.5 1\n",
      "9500 0.0 1\n",
      "10000 0.5 1\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "shape mismatch: indexing arrays could not be broadcast together with shapes (32,) (32,1,512) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-153-57f079914f17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                         \u001b[0mend_multiplier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                         \u001b[0mdoubleQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQ2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m                         \u001b[0mtargetQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdoubleQ\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mend_multiplier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: shape mismatch: indexing arrays could not be broadcast together with shapes (32,) (32,1,512) "
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "update_freq = 4 \n",
    "gamma = .99\n",
    "num_episodes = 10000 # How many episodes of game environment to train network with.\n",
    "pre_train_steps = 10000 # How many steps of random actions before training begins.\n",
    "max_episode_len = 50 # The max allowed length of our episode.\n",
    "save_episode = 1000\n",
    "path = \"../dqn_models\" \n",
    "output_dim = 512\n",
    "tau = 0.001 \n",
    "\n",
    "random_aciton_picking_rate = 1 # Starting chance of random action\n",
    "final_random_action_picking_rate = 0.1\n",
    "annealing_steps = 10000. # How many steps of training to reduce startE to endE.\n",
    "random_action_picking_rate_drop = (random_aciton_picking_rate - final_random_action_picking_rate) / annealing_steps\n",
    "\n",
    "#create lists to contain total rewards and steps per episode\n",
    "jList = []\n",
    "rList = []\n",
    "total_steps = 0\n",
    "myBuffer = experience_buffer()\n",
    "\n",
    "#Make a path for our model to be saved in.\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    primary_network = Double_DQN(output_dim)\n",
    "    target_network = Double_DQN(output_dim)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        for i in range(num_episodes):\n",
    "            episode_buffer = experience_buffer()\n",
    "\n",
    "            s = env.reset()\n",
    "            s = preprocess(s)\n",
    "            d = False\n",
    "            rAll = 0\n",
    "            j = 0\n",
    "\n",
    "            while j < max_episode_len: \n",
    "                j += 1\n",
    "                #Choose an action by greedily choice from the Q-network\n",
    "                if np.random.rand(1) < random_aciton_picking_rate or total_steps < pre_train_steps:\n",
    "                    a = np.random.randint(0, env.action_space.n)\n",
    "                else:\n",
    "                    a = sess.run(primary_network.prediction,\n",
    "                                 feed_dict={primary_network.input_layer : [s]})\n",
    "                    \n",
    "                s1, r, is_t, _ = env.step(a)\n",
    "                s1 = preprocess(s1)\n",
    "                total_steps += 1\n",
    "                episode_buffer.add(np.reshape(np.array([s, a, r, s1, d]),[1, 5]))\n",
    "\n",
    "                if total_steps > pre_train_steps:\n",
    "                    if random_aciton_picking_rate > final_random_action_picking_rate:\n",
    "                        random_aciton_picking_rate -= random_action_picking_rate_drop\n",
    "\n",
    "                    if total_steps % (update_freq) == 0:\n",
    "                        batch = myBuffer.sample(batch_size)\n",
    "                        # Double-DQN update to the target Q-values\n",
    "                        Q1 = sess.run(primary_network.prediction,\n",
    "                                      feed_dict={primary_network.input_layer : batch[:, 3].tolist()})\n",
    "                        \n",
    "                        Q2 = sess.run(target_network.Q,\n",
    "                                      feed_dict={target_network.input_layer : batch[:, 3].tolist()})\n",
    "                        \n",
    "                        end_multiplier = -(batch[:, 4] - 1)\n",
    "                        doubleQ = Q2[range(batch_size), Q1]\n",
    "                        targetQ = batch[:, 2] + (gamma * doubleQ * end_multiplier)\n",
    "                        \n",
    "                        #Update the network with our target values.\n",
    "                        _ = sess.run(primary_network.train_op, \n",
    "                                     feed_dict={\n",
    "                                         primary_network.input_layer : batch[:, 0].tolist(),\n",
    "                                         primary_network.targetQ : targetQ.tolist(), \n",
    "                                         primary_network.actions : batch[:, 1].tolist()})\n",
    "\n",
    "                        updateTarget(updateTargetGraph(tf.trainable_variables(), tau), sess) #Update the target network toward the primary network.\n",
    "                        \n",
    "                rAll += r\n",
    "                s = s1\n",
    "                \n",
    "                if is_t == True:\n",
    "                    break\n",
    "            \n",
    "            myBuffer.add(episode_buffer.buffer)\n",
    "            jList.append(j)\n",
    "            rList.append(rAll)\n",
    "\n",
    "            if i % save_episode == 0 and i > 0:\n",
    "                saver.save(sess, path + '/model-' + str(i) + '.ckpt')\n",
    "                print(\"Saved Model\")\n",
    "            if len(rList) % 10 == 0:\n",
    "                print(total_steps, np.mean(rList[-10:]), random_aciton_picking_rate)\n",
    "                \n",
    "        saver.save(sess,path+'/model-'+str(i)+'.ckpt')\n",
    "        \n",
    "    print(\"Percent of succesful episodes: \" + str(sum(rList)/num_episodes) + \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
